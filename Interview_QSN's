--------: LINUX :-------------
1. Application port is running or not ?
 - command using 'netstat -lntpu'
 - ex- tomcat 8080,nginx 80

2. Memory Check                                                       
 - "TOP" Able to see the CPU Usages: 
 - "free -h" primary memory RAM Usages:
 - "df -h" secondary memory HDD Usages: 
 - "du" directory memory check:
 - uptime: Load Average: 

3. SOFT LINK VS HARD LINK & INODE IN LINUX:
 - Soft Link: It stores the path of the File and works as a shortcut to the file.
           ln  -s [original filename] [link name] 

 - Hard Link: Points directly to the inode of another file
           ln  [original filename] [link name]

 - An inode stores metadata for each file and directory in the file system, 
     such as (File type, File size, Owner ID, Group ID, Read, write and execute permissions)

4. cron-job ?
 - to run the script in a particular interval. 
Ex:
 - * * * * *: the job runs every minute
 - * 0 1 1 1: the job runs every minute of the midnight hour on January 1st and Mondays.

5. What is AWK & SED command
sed -> stream editor that allows users to perform basic text transformations. Insertion, deletion, search and replace(substitution).
e.g unix is great os. 
$sed 's/unix/linux/' geekfile.txt
-- above statement will be replaced by linux is great os. 
e.g. 2: $sed 's/unix/linux/2' geekfile.txt -> Replacing the nth occurrence of a pattern in a line 
e.g. 3: $sed 's/unix/linux/g' geekfile.txt -> Replacing all the occurance of the line

awk -> Awk is mostly used for pattern scanning and processing of text file-in particular data files that are organized by rows and columns
e.g $ awk '{print}' employee.txt
$ awk '{print, $2}' employee.txt ----> to print the second column
NR -> Display field number
NF -> Display last field

6. Directory structure in linux
/root -> for root user, root user can only create, del, modify anything
/home -> This is for specific user, no other user can manipulate anything in this. e.g. /home/bulbul
/bin (binaries) -> all the commands for all the user are available here
/sbin (system binaries) -> commands available only for root users, used for performing major changes in the config file, or any system changes
/dev (Device files) -> Interface between the hardware and software (hardware info and software info)
/media
/etc (editable text configuration) -> all the config files of the application is getting stored here
/sys (System) -> hardware related info is getting stored here
/lib (system libraries) -> libraries required to run the application
/tmp (temporary files) 
/usr (user program)
/var (variable files) -> cache,logs,email files,backup files,spool
/opt (optional application) -> third party tool 

7. Daily/10 cmds in linux
 - ls 
 - ls -ltrh 
 - cd <dirname/>
 - rm -rf <filename> 
 - cat <filename>
 - vi <filename>
 - free -h
 - df -h
 - Grep -i word <filename>
 - find / -name <filename> 

8. How to check public IP, Private IP & Linux system version
 - Private ip: hostname -i
 - Public ip: curl ifconfig.me
 - To see the current ip address on linux: ifconfig
 - Linux OS Version: cat /etc/os-release (or) hostnamectl (or) cat /etc/*release (or) cat /etc/*version 
 - Linux Kernel version: uname -a

9. How to search file's in linux? use of Find & GREP cmd
- Grep -> To search text or strings in a file 
  e.g. Grep -i word <filename>
- Find -> Search the path of file or Directory
  e.g. find <path of file>, find /home/dir1/file1
     find . -name <filename> -> To search in present directory
     find / -name <filename> -> To search in entire filesystem
     find . -name *.war -> To search a file

10. File permission & examples 
chmod -> Change file permissions.
e.g. chmod +rwx Filename
     chmod 774 (user,group,other) Filename
     chmod 664 Filename
    
chown -> Change File owner.
e.g. chown <New owner> Filename

chgrp -> Change group ownership.
e.g. chgrp <New group> Filename

11. How to see if a linux service is running?
- redhat/fedora/centos/amazon linux : systemctl status <service-name>
- ubuntu : service <service-name> status
PACKAGE INSTALLATION:
- redhat/fedora/centos/amazon linux : yum install git -y
- ubuntu : apt-get install git -y

12. What is SSH and how it is used?
- secure shell, used for secure remote access
- provides encrypted communication between client and server

13. 
=============================: GIT :=============================================
1. What is Git stash?
 - Sometimes you want to switch the branches, but you are working on an incomplete part of your current project.
 - Enables you to switch branches without committing the current branch.
 - $ git stash  

2. Difference between git statsh pop and apply?
 - $ git stash pop/ $ git stash apply
 - The difference between git stash pop vs git stash apply is that pop deletes the stash after files are moved into your working directory, 
   while apply does not

3. What is Git Reset?
 - when we want to move the repository back to a specific commit, discarding any changes made after that commit.
 - git reset <commithash>

4. What is Git Revert?
 - Reverts to a specified commit but keeps the history of every other commit made to the code base, 
   and creates a new commit for the reverted changes. 
 - git revert <commit ID>

5. Difference between Git pull and Git clone?
 - Git clone copies all files to the local machine, while git pull only copies the modified files to the local machine

6. What is the difference between Git pull and Fetch?
 - It fetches changes from the remote repository and automatically merges them into the current branch
 - So Git pull is the combination of {Git fetch & Git merge}.
 - git pull origin master 
 - The "git fetch" command only retrieves changes from the remote repository but does not automatically merge them into the current branch.
 - git fetch origin 

7. What is the difference between Git merge and rebase?
 - Git merge keeps the commit sequence intact by combining the histories of the two branches into a single branch
 - Git rebase, on the other hand, rewrites history by putting changes from one branch at the beginning of another, 
   resulting in a more organized, linear project history

8. What is Git Bisect?
 - Git Bisect we use to pick bad commit out of all good commits. 
 - Often developers do some mistakes. For them it is very difficult to pick that commit where mistake is there.
 - They go with building all commits one by one to pick bad commit. But Git bisect made their lives easy. Git bisect divides all commits equally in to two parts (bisecting equally). Now instead of building each commit, they go with building both parts. Where ever bad commit is there, that part build will be failed. We do operation many times till we get bad commit. So Git bisect allows you to find a bad commit out of good commits. You don’t have to trace down the bad commit by hand; git-bisect will do that for you.

9. What is Git squash?
 - To combine multiple commits into one
 - This technique is especially useful when a feature branch has numerous small, 
   incremental commits that clutter the commit history.
 - git merge --squash feature-branch

10. What is Git cherry-pick?
 - Cherry-picking in Git means choosing a commit from one branch and applying it to another.
 - e.g. git cherry-pick <commit-hash>

11. Git Branching strategy ?
 - 1) Master Branch: It containes production code which is stable [ Active Development ]
 - Always Up to date. 
   
 - 2) Development Branch: 
 - Has Pre-Production code . (when we're assigned with new feature we can create a new feature branch frm dev branch, we can create a pull request and merged it with dev branch,and perticular feature branch will be deleted )

 - 3) Feature Branch: 

 - 4) Release Branch: [ Delivering code to the customer ]
 - to support preparation of new prod release. 

 - 5) Hot Fix Branch:  [Quick changes and delivery to customer]
 - to patch prod releases.
 - It should go both in master as well as release branch.

12. Git stages ?
 - Working space
 - Staging Area
 - Local Repo
 - Central repo

13. How to ignore any changes in a file/folder.
 - By creating vi .gitignore and specify the file or folder inside this

=============================: JENKINS :=============================================

1. Jenkins Trigger:
 1. Build Periodically : cron job / 5 astrics, Time Interval Build 
 2. Poll scm : * * * * * , Whenever developer does the code commits automatically Builds the code
 3. Build after other projects are Build
 4. Trigger builds remotely
 5. Manual 
 6. GitHub hook trigger for GITScm polling

2. Jenkins Upstream & downstream jobs? Build - Pipeline
 - Upstream project triggers another project after build
 - Use case of upstream: The "build" pipeline could be an upstream pipeline that triggers the "test" pipeline 
   when the code compilation is successful.
 - Downstream project triggers itself when particular project build completes
 - Use case of Downstream: The "test" pipeline could be a downstream pipeline that waits for the "build" pipeline to complete successfully 
   before it starts running the tests.

3. Multibranch Pipeline with a Webhook on Jenkins.
 - Sometimes it may be necessary to create a pipeline on Jenkins for each Git branch. In this case it could be difficult to create independent pipeline for each branch. 
 - Besides that what if we create or delete a branch in future? So someone has to take care of the pipelines on Jenkins whenever there is change in branches. 
 - That’s where Multibranch pipeline comes into picture.
 - Through Multibranch pipeline we can create a pipeline for each branch in a repository and it also create or remove when there is a change in the branches.

Create a Multibranch Pipeline: 
Ref: https://valaxytech.medium.com/multibranch-pipeline-on-jenkins-with-webhook-a65decede4f8
 - Login to Jenkins GUI
 - Click on “New Item” → Specify a job name → Select “Multibranch Pipeline option”
 - Give Display Name and Description
 - Under Branch Sources → Add source → Chose Git → and provide GitHub URL and Credentials (Credentials are optional if it is public repo)
 - Under Build Configuration → chose Jenkinsfile path. Most of the case it will be under Repo root directory.
 - Under "Behaviour" select branch name or we can add in Jenkinsfile with when expression

Apply and Save the job.
 - Now Jenkins automatically scans the repository and create a job for each branch wherever it finds a Jenkinsfile and initiate first build.

Using Webhook:
 - If you wish to automate the build process in the multibranch pipeline we can use Webhook. This feature is not enabled until we install “Multibranch Scan Webhook Trigger”.
 - This enables an option “scan by webhook” under “Scan Multibranch Pipeline Triggers”. Here we should give a token.
 - Now to enable auto build process we should provide Jenkins URL with token in the GitHub. 
 - For this log into GitHub → settings → Webhooks → Add webhook.
 - Provide Payload URL and Content type as “application/json” and click on Add webhook

4. Jenkins Pipeline: 
 - In Jenkins pipeline is a collection of events / Jobs which are interlinked with one another in a sequence.
 - Jenkins pipeline is a “suite of plugins” which supports implementing & integrating “continuous delivery pipelines” into Jenkins.
 - We integrate pipelines into Jenkins either “Plugins” or “scripts”.
 - It starts from version control to the end users and customers.
 - Jenkins pipelines written in file called “Jenkinsfile”.
 - Pipeline defines the entire build process which included building the application, testing & delivering it.
Two ways to create Jenkins file:
 1. Pipeline script.
 2. pipeline script from SCM.
Pipeline Syntax: Two types:
 - Scripted (1st syntax , Groovy engine , advance scripting capabilities , high flexibility )
 - Declarative (recent addition , easier to get started , pre-defined structure )
Declarative Pipeline:
 - “Pipeline”  must be top level
 - “Agent”
 - “Stages” : where the whole work happens.
 - Under stages we have “stage” i.e build test package deploy(.jenkins/workspace) etc
 - Under stage we have “steps” (script ), sh rm –rf , sh git clone , sh mvn clean etc

5. CONTINOUS INTEGRATION: build stage to Testing Stage. 
 - Continuous integration (CI) is an automated process in DevOps which generate software and its features quickly and efficiently.
 - Developers write the code and stores the code in the centralized repository called version control system i.e in GitHub, Code commit happens continuously. 
 - Code will move to build server where code build, tested and evaluated which generates the artifact like war/jar and stores in artifact repo like Nexus/Jfrog . 
 - A successful CI build may lead to further stages of continuous delivery.
 - If a build fails, the CI system blocks it from progressing to further stages. The team receives a report and repairs the build quickly, typically within minutes.
Benefits of CI:
 - Improved developer productivity
 - Find bugs earlier, fix them faster

Continuous Delivery & Continuous Deployment:
 - Continuous delivery is an extension of continuous integration since it automatically deploys all code changes to a SIT,Dev,LUAT  environment after the build stage.
 - In delivery, there is a final manual approval required before pre-prod & production release. 
 - In the deployment phase, the package is opened and reviewed with a system of automated checks. If the checks fail the package is rejected. 
 - When the checks pass the package is automatically deployed to production. Continuous deployment is the full end to end, automated software deployment pipeline.

6. PROJECT-1  JENKINS-ANSIBLE-NODE / TOMCAT SERVER:
PREREQUISITES: Jenkins server, Ansible server, Tomcat/ansible node
 - Connect tomcat server with Ansible mster then Ansible mstr with Jenkins server.
 - In Jenkins Manage Plugins install “Publish Over SSH”. Install without restart.
 - Publish Over SSH: path to key: /root/.ssh/ id_rsa (private key)
 - ADD server- Server name: Ansible mstr hostname, 
 - Hostname: Public IP, 
 - Usrname: root, 
 - Remote directory: /opt   “Test Configuration – Success or Not” 
Choose Freestyle Project
 - SCM: Github URL
 - Build: Invoke Top Level Maven Target
 - Maven-goals (clean compile test package install)
Write the playbook: In Ansible Mstr
Host: all
Gather_facts: yes
Become: true install jdk & tomcat8, through copy module src file and destination path (var/lib/tomcat/webapps)

 - After compile “Post Build Action”-send build artifact over SSH-
 - Transfer: source file, .war file then remote directory path->
 - Execute command: ansible-playbook playbooks/pb1.yml
 - Ansible Mstr to Tomcat server/Nodes:

7. JENKINS & SLAVE CONFIGURATION:
 Jenkins Server & Jenkins salve Node Communicate with SSH config.
 - In slave have to create workspace /opt/.jenkins
 - Slave node install java 
 - Jenkins server – Manage Nodes & Clouds , New Node , remote root directory - /opt/.jenkins
 - “Restrict where this project can be run”

8. JENKINS ROLES BASED AUTHORISE STRATEGY?
 - Manage User: Create the user
 - Manage Jenkins: manage plugins: “role based auth strategy “
 - Configure global security: Authorization: “Role based strategy “: SAVE
 - Manage and assign roles: Manage roles: roles to add

9. JENKINS BUILD FAILURES:
 - Disk full
 - Mvn goals – clean compile install: spelling error 
 - Compile Errors- Developers 
 - pom.xml - distribution management , pulls any dependecies etc
 

PRE-BUILD CHECKS:
 - Mock builds
 - Proper software version checks
 - Disk sizes
 - Check whether machine is reachable or not.
 - Network Intimate Issue

10. JEKINS BACKUP:
 - Manage Jenkins- Plugins- “thinbackup”, enter
 - Setting- Configure,
backup directory path: /tmp/backup1
 - backup schedule – Using Cron tab
 - Max Number of backups – 2/3
Click On Backup Now & Restore Now.

11. Jenkins Env Variables.
 - BRANCH_NAME
 - CHANGE_ID
 - CHANGE_URL
 - BUILD_ID
 - JOB_NAME
 - BUILD_TAG

12. How to take Backup & restore jenkins configuration and data?
 - backup the jenkins plugins by copying the "plugins" directory in the jenkins home dir to the another location.
 - Backup config files "jenkins.xml" & "secrets" by copying them to another location.
 - we can copy the "job" dir "userContent" dir to another location.

13. Configure new jenkins pipeline but getting error says "no tool maven found", how to resolve this issue?
 - Jenkins unable to locate maven installation directory. 
 - need to provide correct path in jenkins.
 - we need to go to jenkins dashboard-->manage jenkins-->global tool configuration-->add maven --> provide the path.
 - MAVEN_HOME path need to provide.

14. You have a jenkins pipeline that runs unit test for your app, but the pipeline fails when the test fails, 
How would you configure the pipeline to continue running even after is a test fails?
 - We need to use the try-catch block in jenkinsfile.
 - In try block - we need to add jenkinsfile that contains a cmd to run the unit test.
 - Add catch block - will execute if a test fails.

15. What is Multibranch Pipeline and its use?
 - 

16. If we forget Jenkins Password, how would we login back?
 - Go to vi config.xml and make the <useSecurity> tag as false which is Ttue by Default

--------: DOCKER :-------------

1.  VM's                      Container
 - More time to create      - Less time to create
 - Dedicated OS             - Common OS
 - Specific bin/lib         - Common bin/lib
 - Memory wastage           - No memory wastage
 - Low Performance          - High performance
 - Height weight m/c        - Light weight m/c
 - Complex configuration    - Less configuration
 - Memory can't share       - memory can share

2. How to check multiple running containers CPU Usages:
 - # docker stats  --all  -> Provides a snapshot of CPU, memory, disk, and network usage for all running containers
 - # docker stats <containerID>

3. Docker -itd vs -it?
 -itd: interactive terminal in detached mode, running in backend with /bin/bash. 
 -it: interactive terminal, container will create and we are entered into that container.

4. Docker Kill vs Stop?
 - Docker Stop: Sends a SIGTERM signal to the container, which allows it to shut down gracefully and perform any shutdown tasks. 
                If the container doesn't stop within a specified time docker stop will send a SIGKILL signal as well.
 - Docker kill: Sends a SIGKILL signal to the container's main process, immediately terminating it without warning or cleanup. 
                This is useful when a container is unresponsive or needs to be stopped forcefully.

5. Docker Daemon?
 - A docker Deamon (Dokered ) listens for Docker API requests and manages Docker objects such as images, containers, volumes etc. 
 - Also it can communicate with other Docker Deamon to manage services.

6. Docker run and exec ?
 - Docker run creates and starts a new container from an image
 - Docker exec interacts with an already running container

7. How to get an Docker Image?
 - Docker pull <imagename>: pull an image from docker hub
 - Docker commit: convert a container into an image, docker commit  <container id> myimage
 - Docker build: build a script from docker file.

8. Docker Port Mapping: 
  - docker pull nginx
  - docker run -d --name <name> -p 8080:80 nginx:latest
 Docker Volume: Copy the data from local to nginx container: 
  - docker run --name website -v <desktop_path>:</usr/share/nginx/html> -d -p 8080:80 nginx:latest
  - docker exec -it <containername/containerID> bash

9. Docker File??
 - Create an image automatically using a build script.
Ex:
 -  Vi Dockerfile
 - FROM ubuntu
 - MAINTAINER xyz
 - RUN apt-get update
 - RUN echo “HI”
 - CMD [ “echo” “HELLO WORLD”]
 - #docker build –t myimage:1.0 .
 - #docker run -d --name <name> myimage:1.0

10. DOCKER ContainerIP?
 - 172.17.0.1: host
 - docker inspect <containerID>
 
11. DOCKER FILE: Single vs Multiple "RUN" commands ?
 - After building the image all layers stored under "Docker Cache", Suppose we later modify apt-get install by adding extra pkg
 - Docker sees the initial & modified instructions as identical & reuses the cache from previous steps.
 - As a result the apt-get is not executed bcz the build uses the cached version. 
 - So build can potentially get an outdated version of the curl / nginx pkg. 
 - Using RUN apt-get update && apt-get install -y nginx , ensures the Dockerfile installs latest pks. 
 - This technique is known as "cache busting"

12. How many Docker components are there?
 There are three docker components, they are: Docker Client, Docker Host and Docker Registry.
  1. Docker Client: 
    - This component performs “build” and “run” operations for the purpose of opening communication with the docker host.
  2. Docker Host: 
    - This component has the main docker daemon and hosts containers and their associated images. 
    - The daemon establishes a connection with the docker registry.
  3. Docker Registry: 
    - This component stores the docker images. There can be a public registry or a private one.
    - The most famous public registries are Docker Hub and Docker Cloud.

13. what happned to container logs if you stop/restarted the container ? logs deleted or what?
 - we won't be loosing any logs.
 - /var/logs/
 - if container is deleted then will loose it, or we can push it to splunk. 

14. If docker image 2.5gb, what will be cause of concern? how to tackle this?
 - building time will be longer.
 - downloaded error if we're trying to cownload from docker repo.
 - application will be bulkier.
Solutions:
 - Alpine images
 - remove package binaries after installing , never install those are not required.

15. What is docker entrypoint and cmd?
 - In ENTRYPOINT it executes the command as it is & if we provide any new arguments its appended at the end of the instruction.
 - Ex: CMD
 FROM centos:centos7
 CMD ["yum", "-y", "install", "git"]
 docker build -t demo .
 docker run -d --name demo httpd : it's failed as its try to replaced the arg/instruction to httpd.

Ex: ENTRYPOINT
 FROM centos:centos7
 ENTRYPOINT ["yum", "-y", "install", "git"]
 docker build -t demo .
 docker run -d --name demo httpd tree telnet : it's work and its appned at the end of the arg.

Note: We can use both CMD & ENTRYPOINT in a dockerfile.
Ex:
 FROM centos:centos7
 ENTRYPOINT ["yum", "-y", "install"]
 CMD ["git"]
 docker build -t demo .
 docker run -d --name demo tree httpd telnet

16. Docker Compose?
 - It is a tool for running multi-container applications on Docker defined using the Compose file format. 
 - A Compose file is used to define how one or more containers that make up your application are configured.
 - Once we have a Compose file, we can create and start the application with a single command.
 - E.x. docker compose up
 - docker compose down

